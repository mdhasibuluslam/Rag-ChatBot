{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd55777c-a4d6-4090-ac7a-0e56ca2069db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bcdeafe0-2176-4a7f-bf74-f39f363bdd36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI Voice Assistant Project Proposal \\n \\nProject Title: Intelligent Voice Assistant with GUI \\n \\nExecutive Summary \\nAn advanced AI-powered voice assistant capable of understanding natural language commands, \\nperforming various tasks through voice/text input, and providing an intuitive graphical user interface for \\nseamless interaction. \\n \\nProject Overview \\n \\nCategory Details \\nProject Name AI Voice Assistant \\nDeveloper Hasib (Student - Mangrove Institute of Science & Technology) \\nTechnology Stack Python, Tkinter, SpeechRecognition, pyttsx3, OpenWeather API \\nProject Type Desktop Application \\nDevelopment Time 2-3 Weeks \\n \\nProject Objectives \\n \\nPrimary Goals: \\n1. Voice Recognition - Convert speech to text accurately \\n2. Task Automation - Execute commands through voice/text \\n3. User-Friendly Interface - Provide intuitive GUI interaction \\n4. Multi-functional Capabilities - Diverse task handling \\n5. Cross-platform Compatibility - Work on Windows, macOS, Linux \\n \\nKey Features: \\n\\x00 Voice Command Processing \\n\\x00 Text-based Interaction \\n\\x00 Application Management \\n\\x00 Web Browsing Control \\n\\x00 Real-time Weather Updates \\n\\x00 YouTube Integration \\n\\x00 Mathematical Calculations \\n\\x00 Conversational AI Responses \\n \\nTechnical Specifications \\n \\nSystem Architecture \\n \\n    ┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐ \\n    │   User Input    │ →  │  Voice Processor │ →  │  Command        │ \\n    │ (Voice/Text)    │    │  & GUI Interface │    │  Executor       │ \\n    └─────────────────┘    └──────────────────┘    └─────────────────┘ \\n             ↑                       ↓                       ↓ \\n    ┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐ \\n    │   Response      │ ←  │   AI Logic       │ ←  │   External      │ \\n    │   Output        │    │   Engine         │    │   APIs          │ \\n    └─────────────────┘    └──────────────────┘    └─────────────────┘ \\n \\nCore Modules \\n \\n1. Voice Processing Module \\n   - Speech-to-Text conversion \\n   - Text-to-Speech synthesis \\n   - Noise cancellation \\n   - Multiple microphone support \\n \\n2. GUI Interface Module \\n   - Modern dark theme design \\n   - Real-time chat display \\n   - Voice activation controls \\n   - Status indicators \\n \\n3. Command Processing Module \\n   - Natural language understanding \\n   - Intent recognition \\n   - Task routing system \\n   - Error handling \\n \\n4. External Integration Module \\n   - Weather API integration \\n   - Web browser control \\n   - Application launcher \\n   - YouTube search \\n \\nFile Structure \\n \\nAI_Voice_Assistant/ \\n│ \\n├── main_1.py              # Main GUI Application \\n├── processor_1.py         # Voice Processing Engine \\n├── responses.json         # Conversation Database \\n├── commands.json          # Command Configuration \\n├── requirements.txt       # Dependencies \\n├── README.md             # Documentation \\n└── assets/               # Resource Files \\n    ├── icons/ \\n    ├── screenshots/ \\n    └── demo_videos/ \\n \\nTechnical Implementation \\n \\nDependencies & Libraries \\n \\n# Core Libraries \\nspeech_recognition    # Voice recognition \\npyttsx3              # Text-to-speech \\ntkinter              # GUI framework \\nPIL (Pillow)         # Image processing \\nrequests             # API calls \\njson                 # Configuration handling \\ndatetime             # Time/date functions \\nwebbrowser           # Web navigation \\nsubprocess           # Application control \\n \\nKey Algorithms \\n \\n1. Speech Recognition Algorithm \\n   - Google Speech API integration \\n   - Ambient noise adaptation \\n   - Real-time audio processing \\n \\n2. Command Matching Algorithm \\n   - Keyword-based intent detection \\n   - Priority-based command routing \\n   - Context-aware responses \\n \\n3. GUI Rendering Engine \\n   - Asynchronous updates \\n   - Thread-safe operations \\n   - Responsive design \\n \\nUser Interface Design \\n \\nGUI Components \\n- Chat Display Area - Real-time conversation history \\n- Voice Activation Button - Microphone control with visual feedback \\n- Text Input Field - Manual command entry \\n- Status Indicator - System status visualization \\n- Response Display - AI responses with formatting \\n \\nColor Scheme \\n- Primary Color: #1e1e2e (Dark Blue) \\n- Secondary Color: #7289da (Light Blue) \\n- Accent Color: #43b581 (Green) \\n- Text Color: White/Gray \\n \\nFunctional Capabilities \\n \\n1. Voice Commands \\n \\nCommand Type Examples Response \\nBasic Chat \"Hello\", \"How are you?\" Conversational responses \\nApplications \"Open notepad\", \"Open calculator\" Launches specified apps \\nWebsites \"Open youtube\", \"Open google\" Opens in browser \\nSearch \"Search Python tutorial\" Google search results \\nWeather \"Weather in Dhaka\" Real-time weather data \\nTime/Date \"What time is it?\" Current time/date \\nCalculations \"Calculate 15+27\" Mathematical results \\nYouTube \"Play music on YouTube\" YouTube search results \\n \\n2. Text Commands \\n- Same functionality as voice commands \\n- Keyboard shortcut support \\n- Command history tracking \\n \\n3. Smart Features \\n- Context Awareness - Understands follow-up questions \\n- Error Recovery - Handles unrecognized commands gracefully \\n- Multi-language Support - English primary language \\n- Cross-platform - Works on major operating systems \\n \\nWorkflow Process \\n \\nVoice Command Flow \\n \\n1. User clicks voice button → System starts listening \\n2. User speaks command → Audio captured and processed \\n3. Speech converted to text → Google Speech API \\n4. Text analyzed for intent → Command recognition \\n5. Appropriate action executed → Task completion \\n6. Response generated → Text-to-speech output \\n7. Conversation updated → GUI display refreshed \\n \\nText Command Flow \\n \\n1. User types command → Text input field \\n2. Enter key pressed → Command processed \\n3. Intent recognition → Keyword matching \\n4. Action execution → Task performed \\n5. Response displayed → Chat interface updated \\n \\nInnovative Features \\n \\n1. Hybrid Interaction Model \\n- Seamless switch between voice and text \\n- Persistent conversation history \\n- Multi-modal input support \\n \\n2. Smart Command Routing \\n- Priority-based command processing \\n- Fallback mechanisms \\n- Error handling with suggestions \\n \\n3. Extensible Architecture \\n- Modular design for easy expansion \\n- JSON-based configuration \\n- Plugin system for new features \\n \\n4. User Experience Focus \\n- Real-time feedback \\n- Visual status indicators \\n- Intuitive interface design \\n \\nPerformance Metrics \\n \\nAccuracy Standards \\n- Speech Recognition: 90%+ accuracy \\n- Command Execution: 95%+ success rate \\n- Response Time: < 2 seconds \\n- System Uptime: 99% reliability \\n \\nResource Usage \\n- Memory: < 100MB RAM \\n- CPU: < 5% average usage \\n- Storage: < 50MB disk space \\n- Network: Minimal data usage \\n \\nFuture Enhancements \\n \\nShort-term Goals (Next Version) \\n- [ ] Multi-language support \\n- [ ] Custom command creation \\n- [ ] Voice customization \\n- [ ] Advanced NLP integration \\n \\nLong-term Vision \\n- [ ] Machine learning adaptation \\n- [ ] Mobile app companion \\n- [ ] Cloud synchronization \\n- [ ] IoT device integration \\n \\nProject Deliverables \\n \\nDocumentation \\n\\x00 Complete source code \\n\\x00 Installation guide \\n\\x00 User manual \\n\\x00 Technical documentation \\n\\x00 API reference \\n \\nTesting Reports \\n- Unit test cases \\n- Integration testing \\n- User acceptance testing \\n- Performance benchmarking \\n \\nDeployment Package \\n- Executable build \\n- Installation script \\n- Dependency bundle \\n- Configuration files \\n \\nEducational Value \\n \\nSkills Demonstrated \\n- Programming: Advanced Python development \\n- AI/ML: Natural language processing \\n- GUI Development: Tkinter framework mastery \\n- API Integration: RESTful services \\n- Software Architecture: Modular design patterns \\n- Problem Solving: Real-world application development \\n \\nLearning Outcomes \\n- Voice recognition technology understanding \\n- GUI application development skills \\n- API integration techniques \\n- Software testing methodologies \\n- Project management experience \\n \\nConclusion \\n \\nThis AI Voice Assistant project demonstrates comprehensive software development skills, combining \\ncutting-edge technologies with practical usability. It serves as an excellent example of modern Python \\napplication development, showcasing the developer’s ability to create sophisticated, user-friendly \\nsoftware solutions. \\n \\nThe project is ready for demonstration and represents a significant achievement in academic software \\ndevelopment. \\n \\nDeveloper: Hasib \\nInstitution: Mangrove Institute of Science & Technology \\nContact: [Your Email/Phone] \\nDate: [Current Date] \\n \\nThis document provides a comprehensive overview of the AI Voice Assistant project for academic \\nassessment purposes.\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_text_from_pdf(r\"D:\\sodapdf-converted.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e69885e-a224-47e3-b7f4-c75b0b082b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def chunk_text(text, max_chars=800):\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    chunks = []\n",
    "    cur_chunk = \"\"\n",
    "    for s in sentences:\n",
    "        if len(cur_chunk) + len(s) <= max_chars:\n",
    "            cur_chunk += \" \" + s\n",
    "        else:\n",
    "            chunks.append(cur_chunk.strip())\n",
    "            cur_chunk = s\n",
    "    if cur_chunk:\n",
    "        chunks.append(cur_chunk.strip())\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e2f56f7-2b23-46b8-bd51-012ef227660a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_text('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a330e95a-ffa9-4e3c-9cf3-3c9ccb95c226",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
